# ğŸ›’ CorporaciÃ³n Favorita Grocery Sales Forecasting â€“ Guayas

**Live app:** <https://forecasterapp-re6sa3sspcdsceht7piq9s.streamlit.app/>  
**GitHub repo:** <https://github.com/hakimmurphy/forecaster_app>

This multi-part project explores and forecasts grocery sales in Ecuadorâ€™s Guayas province.  
Each notebook adds new capability: rigorous data prep (Part 1), first ML/DL models (Part 2), deeper diagnostics & feature ideas (Part 3), and advanced hyper-tuned modelling (Part 4).

## âœ… Part 1 â€“ Data Preparation & Exploratory Analysis  

| Step | Highlights |
|------|------------|
| **Data Filtering** | subset to Guayas state |
| **Cleaning** | â€¢ filled `onpromotion` nulls<br>â€¢ flipped negative returns to 0<br>â€¢ Z-score outlier removal |
| **Feature Engineering** | calendar vars (day, month, weekday, etc.) + 7-day rolling mean |
| **EDA** | â€¢ line plots of trend â€¢ monthly heat-map â€¢ holiday impact bars â€¢ perishable vs non-perishable split â€¢ focus on top-3 families |

This foundation supports every later model.

---

## ğŸš€ Part 2 â€“ Baseline Modelling & Forecasting  

### ğŸ”¹ XGBoost
* **Inputs:** lag features + calendar dummies  
* **Findings:** captures trend & weekly seasonality; error spikes on extreme days  
* **Use-case:** short-horizon, interpretable SHAP explanations  

### ğŸ”¹ LSTM
* **Inputs:** 30-day sequences (3-D tensors)  
* **Performance:** predicted curve shadows actual curve; good with seasonality; slight lag on sharp jumps  
* **Next:** validate on unseen weeks; benchmark MAE / RMSE vs XGBoost  

---

## ğŸ” Part 3 â€“ Further EDA & Feature-Engineering Insights  

| Analysis | Insight | What to add to models |
|----------|---------|-----------------------|
| **STL decomposition** | clear upward trend + strong 7-day seasonality | trend term / seasonal order 7 |
| **ACF / PACF** | spikes at lags 7, 14, 21; MA(1) behaviour | Suggested: SARIMA (0,1,1)(1,1,0)[7] baseline |
| **Outlier inspection** | single zero-sales dip (early 2014) + extreme holiday peaks | mask / clip outliers |
| **Feature gaps discovered** | holiday lead/lag, on-promotion %, capacity-hit flags, perishable interactions | engineer these for Part 4 |
| **Cross-validation advice** | use `TimeSeriesSplit(gap=7)` to avoid leakage | robust CV pipeline |

--- 

## ğŸš€ Part 4 â€“ Hyper-parameter Tuning & Final Model Selection

| Model | Tuned parameters | Hold-out RMSE | MAE |
|-------|------------------|---------------|-----|
| XGBoost (baseline) | default | 10 600 | 6 900 |
| **XGBoost (tuned)** |  n_estimators = 750, max_depth = 6, eta = 0.05, subsample = 0.8, colsample = 0.9 | **8 900** | **5 600** |
| LSTM (seq = 30) | 1Ã— 64 units, dropout 0.2, epochs 30 | 9 400 | 6 100 |

* XGBoost hyper-search with `TimeSeriesSplit(gap=7)` cut error ~16 % over baseline.  
* Tuned XGBoost serialized (`XGBoost.pkl`) and wired into the Streamlit app.  
* LSTM shows promise but needs more tuning/ensembling for peak-day accuracy.

**Planned next steps**  
1. Quantile forecasts for inventory safety-stock.  
2. Blend XGBoost + LSTM for holiday peaks.  
3. Compare against classical SARIMA benchmark for transparency.

---

## ğŸ›  Tools

| Category | Stack |
|----------|-------|
| Language | Python 3.9 |
| Core libs | Pandas â€¢ NumPy â€¢ Matplotlib â€¢ Seaborn |
| ML / DL  | XGBoost â€¢ Scikit-learn â€¢ TensorFlow / Keras |
| Stats     | statsmodels â€¢ scipy |
| Environment | Jupyter / Google Colab â€¢ Streamlit for interactive app |

---

## ğŸ“„ License
MIT

---

## ğŸ—£ï¸ Author
Hakim Murphy
